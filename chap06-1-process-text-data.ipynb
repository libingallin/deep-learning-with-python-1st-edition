{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理文本数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [n-grams & bag-of-words](#1.-n-gram-和词袋-(bag-of-words))\n",
    "2. [word/character-level one-hot encoding](#2.-单词/字符的-one-hot-encoding)\n",
    "  - [hands-on word-level one-hot encoding](#2.1-手写单词级-ont-hot-编码)\n",
    "  - [hands-on character-level one-hot encoding](#2.2-手写字符级-one-hot-编码)\n",
    "  - [`tf.keras` word-level one-hot encoding](#2.3-tf.keras-实现单词级-one-hot-编码)\n",
    "  - [`tf.keras` character-level one-hot encoding](#2.4-tf.keras-实现字符级-one-hot-编码)\n",
    "  - [one-hot-hashing-trick](#2.5-one-hot-散列技巧-(one-hot-hashing-trick))\n",
    "3. [word embedding](#3.-Word-embedding)\n",
    "  - [hands-on word embedding](#3.1-利用-Embedding-层学习-word-embedding)\n",
    "  - [pretrained word embedding](#3.2-使用-pretrained-word-embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本是最常用的序列数据之一，可以理解为字符序列或单词序列，但最常见的是单词级处理。\n",
    "\n",
    "<font color='crimson'>chap6 介绍的 DL 模型都没有像人类一样真正地理解文本，而只是映射出书面语言的统计结构，但这足以解决许多简单的文本任务。</font>\n",
    "\n",
    "DL 用于自然语言处理是将模式识别应用于单词、句子和段落，这与计算机视觉是将模式识别应用于像素大致相同。\n",
    "\n",
    "<br>\n",
    "\n",
    "**<font color='blue'>文本向量化 (vectorize) 是指将文本转换为数值张量的过程</font>**，方法有：\n",
    "\n",
    "- <font color='blue'>将文本分割为单词 (word)，并将每个单词转换为一个向量</font>\n",
    "\n",
    "\n",
    "- <font color='blue'>将文本分割为字符，并将每个字符转换为一个向量</font>\n",
    "\n",
    "\n",
    "- <font color='blue'>提取单词或字符的 n-gram，并将每个 n-gram 转换为一个向量</font>。 n-gram 是多个连续单词或字符的集合 (n-gram 之间可重叠)\n",
    "\n",
    "将文本分解而成的单元 (单词、字符或 n-gram) 叫作**<font color='red'>标记 (token)</font>** ，将文本分解成标记的过程叫作**<font color='red'>分词 (tokenization)</font>** 。\n",
    "\n",
    "<font color='blue'>所有文本向量化过程都是应用某种分词方案，然后将数值向量与生成的标记相关联。这些向量组合成序列张量，被输入到深度神经网络中。</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "**<font color='crimson'>将向量与 token 相关联的方法：</font>**\n",
    "\n",
    "- <font color='crimson'>对 token 做 one-hot 编码 (one-hot encoding)</font>\n",
    "\n",
    "\n",
    "- <font color='crimson'>token embedding</font>，用于单词，叫作 <font color='crimson'>word embedding</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. n-gram 和词袋 (bag-of-words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='crimson'>n-gram 是从一个句子中提取的 N 个 (或更少) 连续单词 (或字符) 的集合。</font>\n",
    "\n",
    "考虑句子——**\"The cat sat on the mat.\"**\n",
    "\n",
    "- 其 2-gram 集合为：\n",
    "\n",
    "  {\"The\", \"The cat\", \"cat\", \"cat sat\", \"sat\", \"sat on\", \"on\", \"on the\", \"the\", \"the mat\", \"mat\"}\n",
    "\n",
    "\n",
    "- 其 3-gram 集合为：\n",
    "\n",
    "  {\"The\", \"The cat\", \"cat\", \"cat sat\", \"The cat sat\", \"sat\", \"sat on\", \"on\", \"cat sat on\", \"on the\", \"the\", \"sat on the\", \"the mat\", \"mat\", \"on the mat\"}\n",
    "\n",
    "分别称为**<font color='red'>二元语法袋 (bag-of-2-grams)</font>** 和**<font color='red'>三元语法袋 (bag-of-3-grams)</font>** 。**<font color='red'>袋 (bag)</font>** 是指我们处理的是 token 组成的<font color='crimson'>集合</font>，而不是一个列表或序列，即<font color='crimson'> token 没有特定的顺序</font>。这一系列的分词方法叫作**<font color='red'>法袋 (bag-of-words)</font>** 。\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>bag-of-words 是一种不保存顺序的分词方法 (生成的标记组成一个集合，而不是一个序列，舍弃了句子的总体结构)</b>，因此它<b>往往被用于浅层的语言处理模型，而不是 DL 模型</b>。<br><br>\n",
    "提取 n-gram 是一种特征工程，DL 不需要这种死板而又不稳定的方法，并将其替换为分层特征学习。 <b>RNN 和 Conv1D 都能够通过观察连续的单词或字符序列来学习单词组/字符组的数据表示，而无须明确知道这些的存在</b>。<br><br>\n",
    "    <font color='blue'>在使用轻量级的浅层文本处理模型 (如 LR 和 RF) 时，n-gram 是一种功能强大、不可或缺的特征工程工具。</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 单词/字符的 one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one-hot 编码是将标记转换为向量的最常用、最基本的方法。\n",
    "\n",
    "<font color='crimson'>将每个单词/字符与一个唯一的整数索引相关联，然后将这个整数索引 i 转换为长度为 N 的二进制向量 (N 是单词/字符表大小)，这个向量只有第 i 个元 素是 1，其余元素都为 0。</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.558257Z",
     "start_time": "2020-04-19T10:20:58.034010Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Common imports\n",
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 手写单词级 ont-hot 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.564048Z",
     "start_time": "2020-04-19T10:21:01.559766Z"
    }
   },
   "outputs": [],
   "source": [
    "# 单词级的 one-hot 编码\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "token_index = {}\n",
    "for sample in samples:\n",
    "    for word in sample.split():\n",
    "        if word not in token_index:\n",
    "            # 为每个单词指定一个唯一index\n",
    "            # 没有为 index 0 指定单词\n",
    "            token_index[word] = len(token_index) + 1\n",
    "\n",
    "# 对样本进行分词，只考虑每个样本的前 max_length 个单词\n",
    "max_length = 10\n",
    "results = np.zeros(shape=(len(samples),\n",
    "                          max_length,\n",
    "                          # max(token_index.values()) + 1\n",
    "                          len(token_index)+1))\n",
    "\n",
    "for i, sample in enumerate(samples):\n",
    "    # 只考虑每个样本的前 max_length 个单词\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = token_index.get(word)\n",
    "        results[i, j, index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.568586Z",
     "start_time": "2020-04-19T10:21:01.565408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The': 1,\n",
       " 'cat': 2,\n",
       " 'sat': 3,\n",
       " 'on': 4,\n",
       " 'the': 5,\n",
       " 'mat.': 6,\n",
       " 'dog': 7,\n",
       " 'ate': 8,\n",
       " 'my': 9,\n",
       " 'homework.': 10}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_index  # 单词-index 对应关系从 index=0 开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.574693Z",
     "start_time": "2020-04-19T10:21:01.569993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 手写字符级 one-hot 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.578968Z",
     "start_time": "2020-04-19T10:21:01.576075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "string.printable  # 所有可打印的 ASCII 字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.588183Z",
     "start_time": "2020-04-19T10:21:01.583246Z"
    }
   },
   "outputs": [],
   "source": [
    "# character-level 的 one-hot 编码\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "characters = string.printable  # 所有可打印的 ASCII 字符\n",
    "# 为每个单词指定一个唯一index，但不为 index 0 指定单词\n",
    "token_index = dict(zip(characters, range(1, len(characters)+1)))\n",
    "\n",
    "# 只考虑每个样本的前 50 个字符\n",
    "max_length = 50\n",
    "results = np.zeros(shape=(len(samples),\n",
    "                          max_length,\n",
    "                          len(token_index)+1))\n",
    "for i, sample in enumerate(samples):\n",
    "    # 只考虑每个样本的前 50 个字符\n",
    "    for j, character in enumerate(sample[:max_length]):\n",
    "        index = token_index.get(character)\n",
    "        results[i, j, index] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.593959Z",
     "start_time": "2020-04-19T10:21:01.590847Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First (key, value)\n",
      "character: 0, index: 1\n"
     ]
    }
   ],
   "source": [
    "# character-index 对应关系从 index=0 开始\n",
    "for k, v in token_index.items():\n",
    "    print(\"First (key, value)\")\n",
    "    print(\"character: {}, index: {}\".format(k, v))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 `tf.keras` 实现单词级 one-hot 编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.keras.preprocessing.text.Tokenizer(num_words=1000)`** 中 `num_words` 为需要保留的最大单词数 (基于词频)。**只有**最常出现的 `num_words-1` 个单词被保留。\n",
    "\n",
    "默认情况下，删除所有标点符号，将文本转换为空格分隔的单词序列（单词可能包含 `'` 字符）。 这些序列然后被分割成标记列表。然后它们将被索引或向量化。\n",
    "\n",
    "**<font color='blue'>0 是不会被分配给任何单词的保留索引。</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.599711Z",
     "start_time": "2020-04-19T10:21:01.595574Z"
    }
   },
   "outputs": [],
   "source": [
    "# tf.keras 实现 单词级的 one-hot 编码\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "# 基于词频，需要保留的最大单词数，\n",
    "# 只有最常出现的 num_words-1 个被保留。\n",
    "# 0 是不会被分配给任何单词的保留索引\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=1000)\n",
    "# Updates internal vocabulary based on a list of texts.\n",
    "tokenizer.fit_on_texts(samples)\n",
    "\n",
    "# Transforms each text in texts to a sequence of integers.\n",
    "# Only top `num_words-1` most frequent words will be taken into account.\n",
    "# Only words known by the tokenizer will be taken into account.\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "# Convert a list of texts to a Numpy matrix.\n",
    "# one of \"binary\", \"count\", \"tfidf\", \"freq\".\n",
    "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.604538Z",
     "start_time": "2020-04-19T10:21:01.601332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_words': 1000,\n",
       " 'filters': '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
       " 'lower': True,\n",
       " 'split': ' ',\n",
       " 'char_level': False,\n",
       " 'oov_token': None,\n",
       " 'document_count': 2,\n",
       " 'word_counts': '{\"the\": 3, \"cat\": 1, \"sat\": 1, \"on\": 1, \"mat\": 1, \"dog\": 1, \"ate\": 1, \"my\": 1, \"homework\": 1}',\n",
       " 'word_docs': '{\"on\": 1, \"mat\": 1, \"the\": 2, \"cat\": 1, \"sat\": 1, \"my\": 1, \"dog\": 1, \"homework\": 1, \"ate\": 1}',\n",
       " 'index_docs': '{\"4\": 1, \"5\": 1, \"1\": 2, \"2\": 1, \"3\": 1, \"8\": 1, \"6\": 1, \"9\": 1, \"7\": 1}',\n",
       " 'index_word': '{\"1\": \"the\", \"2\": \"cat\", \"3\": \"sat\", \"4\": \"on\", \"5\": \"mat\", \"6\": \"dog\", \"7\": \"ate\", \"8\": \"my\", \"9\": \"homework\"}',\n",
       " 'word_index': '{\"the\": 1, \"cat\": 2, \"sat\": 3, \"on\": 4, \"mat\": 5, \"dog\": 6, \"ate\": 7, \"my\": 8, \"homework\": 9}'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the tokenizer configuration as Python dictionary.\n",
    "tokenizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.609076Z",
     "start_time": "2020-04-19T10:21:01.606001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The cat sat on the mat.', 'The dog ate my homework.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.613810Z",
     "start_time": "2020-04-19T10:21:01.610589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.618253Z",
     "start_time": "2020-04-19T10:21:01.615223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.623591Z",
     "start_time": "2020-04-19T10:21:01.619806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 `tf.keras` 实现字符级 one-hot 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.629354Z",
     "start_time": "2020-04-19T10:21:01.625329Z"
    }
   },
   "outputs": [],
   "source": [
    "# tf.keras 实现字符级的 one-hot 编码\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=1000,\n",
    "                                                  char_level=True)\n",
    "# Updates internal vocabulary based on a list of texts.\n",
    "tokenizer.fit_on_texts(samples)\n",
    "\n",
    "# Transforms each text in texts to a sequence of integers.\n",
    "# Only top `num_words-1` most frequent words will be taken into account.\n",
    "# Only words known by the tokenizer will be taken into account.\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "# Convert a list of texts to a Numpy matrix.\n",
    "# one of \"binary\", \"count\", \"tfidf\", \"freq\".\n",
    "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.634469Z",
     "start_time": "2020-04-19T10:21:01.631098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 1,\n",
       " 't': 2,\n",
       " 'e': 3,\n",
       " 'h': 4,\n",
       " 'a': 5,\n",
       " 'o': 6,\n",
       " 'm': 7,\n",
       " '.': 8,\n",
       " 'c': 9,\n",
       " 's': 10,\n",
       " 'n': 11,\n",
       " 'd': 12,\n",
       " 'g': 13,\n",
       " 'y': 14,\n",
       " 'w': 15,\n",
       " 'r': 16,\n",
       " 'k': 17}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index  # index 从 1 开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.639346Z",
     "start_time": "2020-04-19T10:21:01.636047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 one-hot 散列技巧 (one-hot hashing trick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one-hot 编码的一种变体是所谓的 **<font color='red'>one-hot 散列技巧 (one-hot hashing trick)</font>**。\n",
    "\n",
    "<font color='crimson'>如果词表中唯一标记的数量太大而无法直接处理，就可以使用这种技巧。</font>\n",
    "\n",
    "这种方法<font color='crimson'>没有为每个单词显式分配一个索引并将这些索引保存在一个字典中，而是将单词散列编码为固定长度的向量，通常用一个非常简单的散列函数来实现</font>。\n",
    "\n",
    "这种方法的主要优点在于，它<font color='blue'>避免了维护一个显式的单词索引，从而节省内存并允许数据的在线编码 (在读取完所有数据之前，你就可以立刻生成标记向量)</font>。\n",
    "    \n",
    "这种方法有一个缺点，就是<font color='blue'>可能会出现散列冲突 (hash collision)，即两个不同的单词可能具有相同的散列值，随后任何机器学习模型观察这些散列值，都无法区分它们所对应的单词</font>。如果散列空间的维度远大于需要散列的唯一标记的个数，散列冲突的可能性会减小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.645084Z",
     "start_time": "2020-04-19T10:21:01.640759Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用散列技巧的单词级 one-hot 编码\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "# 将单词保存为长度为 1000 的向量\n",
    "# 如果单词数量接近于 1000 个（或更多），那么会遇到散列冲突，会降低准确性\n",
    "dimensionality = 1000\n",
    "max_length = 100\n",
    "\n",
    "results = np.zeros(shape=(len(samples), max_length, dimensionality))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        # 将单词散列为 0～1000 范围内的一个随机整数 index\n",
    "        index = abs(hash(word)) % dimensionality\n",
    "        results[i, j, index] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.650473Z",
     "start_time": "2020-04-19T10:21:01.646669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将单词与向量相关联还有另一种常用的强大方法，就是使用密集的词向量 (word vector)， 也叫**<font color='red'>词嵌入 (word embedding)</font>**。\n",
    "\n",
    "- <font color='blue'>one-hot 编码得到的向量是二进制的、稀疏的 (绝大部分元素都 是 0)、维度很高的 (维度大小等于词表中的单词个数)</font>\n",
    "\n",
    "\n",
    "- <font color='blue'>word embedding是低维的浮点数向量(即密集向量，与稀疏向量相对)</font>\n",
    "\n",
    "<font color='crimson'>与 one-hot 编码得到的词向量不同，词嵌入是从数据中学习得到的。</font>\n",
    "\n",
    "<font color='crimson'>常见的 word embedding 维度是 256、512 或 1024 (处理非常大的词表时)</font>。与此相对，one-hot 编码的词向量维度通常为 20000 或更高 (对应包含 20000 个标记的词表)。因此，<font color='crimson'>word embedding 可以将更多的信息塞入更低的维度中</font>。\n",
    "\n",
    "![word_embedding](figs/chap06-figs/word_embedding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b><center>获得 word embedding 的 2 种方法</center></b><Br>\n",
    "    1) <b>在完成主任务 (比如文档分类或情感预测) 的同时学习词嵌入。</b>在这种情况下，一开始是随机的词向量，然后对这些词向量进行学习，其学习方式与学习神经网络的权重相同。<br><br>\n",
    "    2) <b>在不同于待解决问题的 ML 任务上预计算好 word embedding，然后将其加载到模型中</b>。这些 word embedding 叫作<font color='red'>预训练词嵌入 (pretrained word embedding)</font>。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 利用 `Embedding` 层学习 word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='crimson'>要将一个词与一个密集向量相关联，最简单的方法就是随机选择向量。这种方法的问题在于，得到的嵌入空间没有任何结构。</font>\n",
    "\n",
    "> accurate 和 exact 两个词的嵌入可能完全不同，尽管它们在大多数句子里都是可以互换的。DNN 很难对这种杂乱的、非结构化的嵌入空间进行学习。\n",
    "\n",
    "\n",
    "<font color='blue'>词向量之间的几何关系应该表示这些词之间的语义关系。 word embedding 的作用应该是将人类的语言映射到几何空间中。</font>例如，<font color='crimson'>在一个合理的 word embedding 空间中，同义词应该被嵌入到相似的词向量中。</font> 一般来说，<font color='crimson'>任意两个词向量之间的几何距离 (比如 L2 距离) 应该和这两个词的语义距离有关 (表示不同事物的词被嵌入到相隔很远的点，而相关的词则更加靠近)</font>。除了距离，你可能<font color='crimson'>还希望嵌入空间中的特定方向也是有意义的</font>。为了更清楚地说明这一点，我们来 看一个具体示例。\n",
    "\n",
    "> 图中，四个词被嵌入在二维平面上，这四个词分别是 cat (猫)、dog (狗)、wolf (狼) 和 tiger (虎)。对于我们这里选择的向量表示，这些词之间的某些语义关系可以被编码为几何 变换。例如，从 cat 到 tiger 的向量与从 dog 到 wolf 的向量相等，这个向量可以被解释为“从宠 物到野生动物”向量。同样，从 dog 到 cat 的向量与从 wolf 到 tiger 的向量也相等，它可以被解 释为“从犬科到猫科”向量。\n",
    "\n",
    "在真实的 word embedding 空间中，常见的有意义的几何变换的例子包括“性别”向量和“复数”向量。 例如，将 king (国王) 向量加上 female (女性) 向量，得到的是 queen (女王) 向量。将 king (国王) 向量加上 plural (复数) 向量，得到的是 kings 向量。 **word embedding 空间通常具有几千个这种可解释的、 并且可能很有用的向量。**\n",
    "\n",
    "有没有一个理想的 word embedding 空间，可以完美地映射人类语言，并可用于所有自然语言处理任 务?可能有，但我们尚未发现。此外，也不存在人类语言(human language)这种东西。世界上有许多种不同的语言，而且它们不是同构的，因为语言是特定文化和特定环境的反射。但从更实际的角度来说，**<font color='crimson'>一个好的 word embedding 空间在很大程度上取决于你的任务</font>**。英语电影评论情感分析 模型的完美 word embedding 空间，可能不同于英语法律文档分类模型的完美 word embedding 空间，<font color='crimson'>因为某些语义关系的重要性因任务而异</font>。\n",
    "\n",
    "因此，**<font color='blue'>合理的做法是对每个新任务都学习一个新的嵌入空间</font>**。幸运的是，反向传播让这种学习变得很简单，而 Keras 使其变得更简单。我们要做的就是学习一个层的权重，这个层就是 **`Embedding`** 层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.657902Z",
     "start_time": "2020-04-19T10:21:01.651950Z"
    }
   },
   "outputs": [],
   "source": [
    "# Turns positive integers (indexes) into dense vectors of fixed size.\n",
    "# This layer can ONLY be used as the first layer in a model.\n",
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    # Size of the vocabulary, i.e. maximum integer index + 1.\n",
    "    input_dim=1000,\n",
    "    # Dimension of the dense embedding.\n",
    "    output_dim=64,\n",
    "    #  Length of input sequences, when it is constant. \n",
    "    input_length=None)\n",
    "# embedding_layer = tf.keras.layers.Embedding(1000, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.693449Z",
     "start_time": "2020-04-19T10:21:01.659472Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 10, 64)            64000     \n",
      "=================================================================\n",
      "Total params: 64,000\n",
      "Trainable params: 64,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # the largest integer (i.e. word index) in the input should be no larger\n",
    "    # than 999 (vocabulary size)\n",
    "    tf.keras.layers.Embedding(1000, 64, input_length=10)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.762228Z",
     "start_time": "2020-04-19T10:21:01.695167Z"
    }
   },
   "outputs": [],
   "source": [
    "input_array = np.random.randint(1000, size=(32, 10))\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "assert output_array.shape == (32, 10, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以将 `Embedding` 层理解为一个字典，将整数索引 (表示特定单词) 映射为密集向量。它接收整数作为输入，并在内部字典中查找这些整数，然后返回相关联的向量。`Embedding` 层实际上是一种字典查找 (look-up)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.767099Z",
     "start_time": "2020-04-19T10:21:01.764025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model input shape: (samples, input_length)\n",
    "model.input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='crimson'>Embedding 层的输入是一个二维整数张量，shape 为 (samples, input_length)， 每个元素是一个整数序列。</font>它<font color='crimson'>能够嵌入长度可变的序列</font>，例如，对于前一个例子中的 Embedding 层，你可以输入形状为 (32, 10) (32 个长度为 10 的序列组成的批量) 或 (64, 15) (64 个长度为 15 的序列组成的批量) 的批量。<font color='crimson'>不过每个 batch 数据中的所有序列必须具有相同的长度</font> (因为需要将它们打包成一个张量)，所以<font color='crimson'>较短的序列应该用 0 填充，较长的序列应该被截断</font>。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:01.771843Z",
     "start_time": "2020-04-19T10:21:01.768587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 10, 64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model input shape: (samples, input_length, embedding_dimensionality)\n",
    "# 可以用 RNN 层或 Conv1D 层来处理这个三维张量\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='blue'>将一个 Embedding 层实例化时，它的权重 (即标记向量的内部字典) 最开始是随机的，与其他层一样。在训练过程中，利用反向传播来逐渐调节这些词向量，改变空间结构以便下游模型可以利用。一旦训练完成，嵌入空间将会展示大量结构，这种结构专门针对训练模型所要解决的问题。</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:06.303193Z",
     "start_time": "2020-04-19T10:21:01.778252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "# Load the IMDB data\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "max_features = 10000  # 作为特征的单词个数\n",
    "maxlen = 20  # 每个 sample 只取前 20 个单词\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:06.312300Z",
     "start_time": "2020-04-19T10:21:06.308651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为将电影评论限制为前 10000 个最常见的单词，所以数据集中最大的 index 为 9999，最小的 index 为 1，0 是不会被分配给任何单词的保留索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:06.511768Z",
     "start_time": "2020-04-19T10:21:06.314073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9999, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(max(sample) for sample in x_train), min(min(sample) for sample in x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:06.884273Z",
     "start_time": "2020-04-19T10:21:06.513515Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess the sequences\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "# Pads sequences to the same length.\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen, dtype='int32',\n",
    "                                 padding='pre', truncating='pre', value=0.0)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen, dtype='int32',\n",
    "                                 padding='pre', truncating='pre', value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:06.891344Z",
     "start_time": "2020-04-19T10:21:06.886280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 20), (25000, 20))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:06.956521Z",
     "start_time": "2020-04-19T10:21:06.894087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential([\n",
    "    # The input shape is `(samples, maxlen)`.\n",
    "    # Argument `input_length` is required\n",
    "    # if you are going to connect `Flatten` then `Dense` layers upstream\n",
    "    # (without it, the shape of the dense outputs cannot be computed).\n",
    "    tf.keras.layers.Embedding(10000, 8, input_length=maxlen),\n",
    "    # After the `Embedding` layer, \n",
    "    # our activations have shape `(samples, maxlen, 8)`.\n",
    "\n",
    "    # Flatten the 3D tensor of embeddings\n",
    "    # into a 2D tensor of shape `(samples, maxlen * 8)`\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    # Add the classifier on top\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:13.941671Z",
     "start_time": "2020-04-19T10:21:06.958339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 49us/sample - loss: 0.6709 - acc: 0.5084 - val_loss: 0.6221 - val_acc: 0.5778\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 1s 33us/sample - loss: 0.5456 - acc: 0.6842 - val_loss: 0.5294 - val_acc: 0.7080\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 1s 33us/sample - loss: 0.4622 - acc: 0.7642 - val_loss: 0.5032 - val_acc: 0.7360\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 1s 33us/sample - loss: 0.4209 - acc: 0.7941 - val_loss: 0.4960 - val_acc: 0.7388\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 1s 33us/sample - loss: 0.3930 - acc: 0.8116 - val_loss: 0.4962 - val_acc: 0.7402\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 1s 33us/sample - loss: 0.3708 - acc: 0.8273 - val_loss: 0.5020 - val_acc: 0.7508\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 1s 33us/sample - loss: 0.3513 - acc: 0.8390 - val_loss: 0.5070 - val_acc: 0.7434\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 1s 33us/sample - loss: 0.3336 - acc: 0.8502 - val_loss: 0.5149 - val_acc: 0.7468\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 1s 34us/sample - loss: 0.3163 - acc: 0.8612 - val_loss: 0.5241 - val_acc: 0.7452\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 1s 33us/sample - loss: 0.3003 - acc: 0.8702 - val_loss: 0.5334 - val_acc: 0.7408\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    # The validation data is selected from the last samples\n",
    "    # in the `x` and `y` data provided, before shuffling. \n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到的验证精度约为 75%，考虑到仅查看每条评论的前 20 个单词，这个结果还是相当不错 的。\n",
    "\n",
    "但请注意，**<font color='crimson'>仅仅将嵌入序列展开并在上面训练一个 `Dense` 层，会导致模型对输入序列中的每个单词单独处理，而没有考虑单词之间的关系和句子结构</font>** ( 举个例子，这个模型可能会将 this movie is a bomb 和 this movie is the bomb 两条都归为负面评论)。**<font color='crimson'>更好的做法是在嵌入序列上添加循环层或一维卷积层，将每个序列作为整体来学习特征。</font>** 这也是接下来几节的重点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 使用 pretrained word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='crimson'>当可用的训练数据很少，以至于只用手头数据无法学习适合特定任务的 word embedding，可以从预计算的嵌入空间中加载嵌入向量 (你知道这个嵌入空间是高度结构化的，并且具有有用的属性，即抓住了语言结构的一般特点)，而不是在解决问题的同时学习词嵌入。</font>\n",
    "\n",
    "<font color='blue'>在 nlp 中使用预训练的 word embedding，其背后的原理与在图像分类中使用预训练的 convnet 是一样的：没有足够的数据来自己学习真正强大的特征，但需要的特征应该是非常通用的，比如常见的视觉特征或语义特征。在这种情况下，重复使用在其他问题上学到的特征，这种做法是有道理的。</font>\n",
    "\n",
    "- <font color='blue'>word2vec</font> 算法由 Google 的 Tomas Mikolov 于 2013 年开发，其维度抓住了特定的语义属性，比如性别。\n",
    "\n",
    "\n",
    "- <font color='blue'>GloVe</font> (global vectors for word representation，词表示全局向量)，由斯坦福大学的研究人员于 2014 年开发。这种嵌入方法基于对词共现统计矩阵进行因式分解。其开发者已经公开了数百万个英文标记的预计算嵌入，它们都是从维基百科数据和 Common Crawl 数据得到的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='blueviolet'>1. 下载数据：</font>**\n",
    "\n",
    "此处将使用 pretrained word embedding，将从头开始，先下载 IMDB 原始文本数据，而不是使用 Keras 内置的已经预先分好词的 IMDB 数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:15.034521Z",
     "start_time": "2020-04-19T10:21:13.942990Z"
    }
   },
   "outputs": [],
   "source": [
    "imdb_dir = '/Users/bingli/datasets/aclImdb/'\n",
    "train_dir = os.path.join(imdb_dir, 'train')\n",
    "\n",
    "texts, labels = [], []\n",
    "for label_type in ['pos', 'neg']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for file_name in os.listdir(dir_name):\n",
    "        if file_name[-4:] == '.txt':\n",
    "            with open(os.path.join(dir_name, file_name), 'r') as f:\n",
    "                texts.append(f.read())\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='blueviolet'>2. 对数据进行分词：</font>**\n",
    "\n",
    "对文本进行分词，并将其划分为训练集和验证集。\n",
    "\n",
    "因为 <font color='crimson'>pretrained word embedding 对训练数据很少的问题特别有用</font> (否则，针对于具体任务的嵌入可能效果更好)， 所以我们又添加了以下限制: 将训练数据限定为前 200 个样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:21.023539Z",
     "start_time": "2020-04-19T10:21:15.036189Z"
    }
   },
   "outputs": [],
   "source": [
    "# pretrained word embedding 对训练数据很少的问题特别有用\n",
    "training_samples = 200\n",
    "val_samples = 10000\n",
    "\n",
    "maxlen = 100       # 在 100 个单词截断评论\n",
    "max_words = 10000  # 只考虑数据集中前 10000 个最常见的单词\n",
    "\n",
    "\n",
    "# 基于词频，需要保留的最大单词数，\n",
    "# 只有最常出现的 num_words-1 个被保留。\n",
    "# 0 是不会被分配给任何单词的保留索引\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:21.032335Z",
     "start_time": "2020-04-19T10:21:21.025131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88582 unique tokens.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 88582)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(\"Found {} unique tokens.\".format(len(word_index)))\n",
    "\n",
    "min(word_index.values()), max(word_index.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:21.126152Z",
     "start_time": "2020-04-19T10:21:21.034507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只有数据中最常出现的 num_words-1=10000-1=9999 个单词被保留\n",
    "max(max(sequence) for sequence in sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:21.348652Z",
     "start_time": "2020-04-19T10:21:21.127539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 100)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad the sequence to the same length\n",
    "data = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    sequences,  # List of lists, where each element is a sequence.\n",
    "    maxlen=maxlen,  # maximum length of all sequences.\n",
    "    padding='pre',  # pad either before or after each sequence.\n",
    "    # remove values from sequences larger than\n",
    "    # `maxlen`, either at the beginning or at the end of the sequences.\n",
    "    truncating='pre',\n",
    "    value=0.0,  # Float or String, padding value.\n",
    ")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function **transforms a list of `num_samples` sequences (lists of integers) into a 2D Numpy array of shape `(num_samples, num_timesteps`)**. `num_timesteps` is either the maxlen argument if provided, or the length of the longest sequence otherwise.\n",
    "\n",
    "Sequences that are shorter than `num_timesteps` are padded with value at the end.\n",
    "\n",
    "Sequences longer than `num_timesteps` are truncated so that they fit the desired length. \n",
    "\n",
    "The position where padding or truncation happens is determined by the arguments padding and truncating, respectively.\n",
    "\n",
    "Pre-padding is the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:21.362318Z",
     "start_time": "2020-04-19T10:21:21.349915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 100), (10000, 100))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.asarray(labels)\n",
    "\n",
    "# Shuffle the data\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "# Split the data\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples:training_samples + val_samples]\n",
    "y_val = labels[training_samples:training_samples + val_samples]\n",
    "\n",
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='blueviolet'>3. 预处理 pretrained word embedding：</font>**\n",
    "\n",
    "对 pretrained word embedding 文件 (.txt 文件) 进行解析，构建一个单词（字符）映射为其向量表示（数值向量）的 index。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:21.490996Z",
     "start_time": "2020-04-19T10:21:21.363915Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the -0.038194 -0.24487 0.72812 -0.39961 0.083172 0.043953 -0.39141 0.3344 -0.57545 0.087459 0.28787 -0.06731 0.30906 -0.26384 -0.13231 -0.20757 0.33395 -0.33848 -0.31743 -0.48336 0.1464 -0.37304 0.34577 0.052041 0.44946 -0.46971 0.02628 -0.54155 -0.15518 -0.14107 -0.039722 0.28277 0.14393 0.23464 -0.31021 0.086173 0.20397 0.52624 0.17164 -0.082378 -0.71787 -0.41531 0.20335 -0.12763 0.41367 0.55187 0.57908 -0.33477 -0.36559 -0.54857 -0.062892 0.26584 0.30205 0.99775 -0.80481 -3.0243 0.01254 -0.36942 2.2167 0.72201 -0.24978 0.92136 0.034514 0.46745 1.1079 -0.19358 -0.074575 0.23353 -0.052062 -0.22044 0.057162 -0.15806 -0.30798 -0.41625 0.37972 0.15006 -0.53212 -0.2055 -1.2526 0.071624 0.70565 0.49744 -0.42063 0.26148 -1.538 -0.30223 -0.073438 -0.28312 0.37104 -0.25217 0.016215 -0.017099 -0.38984 0.87424 -0.72569 -0.51058 -0.52028 -0.1459 0.8278 0.27062\r\n",
      ", -0.10767 0.11053 0.59812 -0.54361 0.67396 0.10663 0.038867 0.35481 0.06351 -0.094189 0.15786 -0.81665 0.14172 0.21939 0.58505 -0.52158 0.22783 -0.16642 -0.68228 0.3587 0.42568 0.19021 0.91963 0.57555 0.46185 0.42363 -0.095399 -0.42749 -0.16567 -0.056842 -0.29595 0.26037 -0.26606 -0.070404 -0.27662 0.15821 0.69825 0.43081 0.27952 -0.45437 -0.33801 -0.58184 0.22364 -0.5778 -0.26862 -0.20425 0.56394 -0.58524 -0.14365 -0.64218 0.0054697 -0.35248 0.16162 1.1796 -0.47674 -2.7553 -0.1321 -0.047729 1.0655 1.1034 -0.2208 0.18669 0.13177 0.15117 0.7131 -0.35215 0.91348 0.61783 0.70992 0.23955 -0.14571 -0.37859 -0.045959 -0.47368 0.2385 0.20536 -0.18996 0.32507 -1.1112 -0.36341 0.98679 -0.084776 -0.54008 0.11726 -1.0194 -0.24424 0.12771 0.013884 0.080374 -0.35414 0.34951 -0.7226 0.37549 0.4441 -0.99059 0.61214 -0.35111 -0.83155 0.45293 0.082577\r\n"
     ]
    }
   ],
   "source": [
    "# pretrained word embedding 文件\n",
    "glove_dir = '/Users/bingli/models/glove.6B/'\n",
    "glove_embedding_path = os.path.join(glove_dir, 'glove.6B.100d.txt')\n",
    "\n",
    "!head -n 2 /Users/bingli/models/glove.6B/glove.6B.100d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:30.022435Z",
     "start_time": "2020-04-19T10:21:21.493444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# 解析 Glove word embedding 文件\n",
    "embedding_index = {}  # {word: embedding_vector}\n",
    "with open(glove_embedding_path, 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs\n",
    "\n",
    "print('Found {} word vectors.'.format(len(embedding_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='crimson'>构建一个可以加载到 `Embedding` 层中的嵌入矩阵。</font>**\n",
    "\n",
    "它必须是一个形状为 **`(max_words, embedding_dim)`** 的矩阵，<font color='crimson'>对于单词索引 (在分词时构建) 中索引为 i 的单词， 这个矩阵的元素 i 就是这个单词对应的 `embedding_dim` 维向量。</font>\n",
    "\n",
    "**<font color='blue'>注意，索引 0 不应该代表任何 单词或标记，它只是一个占位符。</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:30.125074Z",
     "start_time": "2020-04-19T10:21:30.024643Z"
    }
   },
   "outputs": [],
   "source": [
    "# 构建一个可以加载到 `Embedding` 层的词嵌入矩阵\n",
    "embedding_dim = 100\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, index in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        # embedding_index 中招不到的词，其潜入向量全为 0\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:30.130362Z",
     "start_time": "2020-04-19T10:21:30.126904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:30.138076Z",
     "start_time": "2020-04-19T10:21:30.132159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.10197   ,  0.24378   ,  0.026815  , -0.13862   ,  0.043288  ,\n",
       "         0.11233   , -0.20103   , -0.50401002, -0.033329  , -0.029917  ,\n",
       "        -0.13337   ,  0.29372999,  0.53367001,  0.16546001,  0.1469    ,\n",
       "         0.19155   , -0.24087   ,  0.20281   ,  0.60333002, -0.40316999,\n",
       "        -0.64002001,  0.10595   ,  0.16371   , -0.45346999,  0.3594    ,\n",
       "         0.73284   , -0.32778001,  0.30529001,  0.30746001, -0.15313999,\n",
       "         0.34628999, -0.59846002,  0.68567997, -0.17251   , -0.70450002,\n",
       "         0.55811   , -0.19467001, -0.65469003,  0.25960001,  0.40426999,\n",
       "         0.80255997, -0.12756   ,  0.27770001, -0.050226  , -0.43445   ,\n",
       "         0.059835  ,  0.28907001,  0.11287   ,  0.71569002, -0.12288   ,\n",
       "        -0.43505999,  0.18784   , -0.25465   , -0.02254   ,  0.8854    ,\n",
       "         1.00929999,  0.27625999, -0.08134   , -0.81564999,  0.079341  ,\n",
       "         0.17938   ,  0.45721999, -0.27111   ,  0.38727999,  0.02146   ,\n",
       "        -0.00248   ,  0.42162001, -0.14391001,  0.18471999, -0.33658001,\n",
       "         0.46779999,  0.36655   ,  0.27698001, -0.28760001, -0.062973  ,\n",
       "        -0.012474  , -0.34229001,  0.20142999,  0.44281   , -0.27772   ,\n",
       "         0.45333999, -0.041024  ,  0.32187   ,  0.20855001, -0.14734   ,\n",
       "        -0.43706   ,  0.13064   ,  0.28849   , -0.025354  ,  0.28681001,\n",
       "        -0.063975  , -0.099861  ,  0.33563   ,  0.33390999,  0.048235  ,\n",
       "        -0.33678001,  0.15031999, -0.27248001,  0.13527   ,  0.03095   ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='blueviolet'>4. 构建模型</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:30.182240Z",
     "start_time": "2020-04-19T10:21:30.139849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_words,\n",
    "                              output_dim=embedding_dim,\n",
    "                              input_length=maxlen),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:30.188502Z",
     "start_time": "2020-04-19T10:21:30.184167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 100), (None, 100, 100))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input shape : (samples, input_length)\n",
    "# output shape: (samples, input_length, output_dim)\n",
    "model.layers[0].input_shape, model.layers[0].output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:30.193954Z",
     "start_time": "2020-04-19T10:21:30.190440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 100])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding 层只有一个权重，其 shape 为 (input_dim, output_dim)\n",
    "model.layers[0].weights[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='blueviolet'>5. 在模型中加载 pretrained word embedding</font>**\n",
    "\n",
    "**`Embedding` 层只有一个权重矩阵，是一个二维的浮点数矩阵，其中每个元素 i 是与索引 i 相关联的词向量。够简单。将准备好的 GloVe 矩阵加载到 Embedding 层中，即模型的第一层。**\n",
    "\n",
    "**需要冻结 `Embedding` 层 (即将其 `trainable` 属性设为 `False`)**，其原理和预训练的 convnet 相同。\n",
    "\n",
    "<font color='crimson'>如果一个模型的一部分是经过预训练的 (如 `Embedding` 层)，而另一部分是随机初始化的 (如分类器)，那么在训练期间不应该更新预训练的部分，以避免丢失它们所保存的信息。随机初始化的层会引起较大的梯度更新，会破坏已经学到的特征。</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:30.200561Z",
     "start_time": "2020-04-19T10:21:30.195757Z"
    }
   },
   "outputs": [],
   "source": [
    "# 将 pertained word embedding 加载到 Embedding 层中\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "# 冻结 Embedding 层，以避免丢失它们保存的信息\n",
    "model.layers[0].trainabel = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='blueviolet'>6. 训练模型</font>**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:34.008237Z",
     "start_time": "2020-04-19T10:21:30.202486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 4ms/sample - loss: 0.7259 - acc: 0.5000 - val_loss: 0.7284 - val_acc: 0.4992\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.4833 - acc: 0.7650 - val_loss: 0.7885 - val_acc: 0.4998\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.3510 - acc: 0.8650 - val_loss: 0.8857 - val_acc: 0.4989\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.2466 - acc: 0.9300 - val_loss: 0.9688 - val_acc: 0.4963\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.1648 - acc: 0.9600 - val_loss: 1.0716 - val_acc: 0.4973\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.1080 - acc: 0.9650 - val_loss: 1.1840 - val_acc: 0.4970\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0703 - acc: 0.9850 - val_loss: 1.3056 - val_acc: 0.4945\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0440 - acc: 0.9950 - val_loss: 1.4141 - val_acc: 0.4978\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0278 - acc: 1.0000 - val_loss: 1.5186 - val_acc: 0.4974\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 1.6342 - val_acc: 0.4992\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val))\n",
    "model.save('./models/chap06-models/pretrained_glove_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:34.017907Z",
     "start_time": "2020-04-19T10:21:34.009844Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    history_dict = history.history\n",
    "\n",
    "    loss_values = history_dict['loss']\n",
    "    val_loss_values = history_dict['val_loss']\n",
    "    acc = history_dict['acc']\n",
    "    val_acc = history_dict['val_acc']\n",
    "\n",
    "    epochs = [i + 1 for i in history.epoch]\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(14, 4.2))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(epochs, loss_values, 'c+-', label='Training loss')\n",
    "    plt.plot(epochs, val_loss_values, 'm.-', label='Val loss')\n",
    "    plt.xlabel('Epochs', fontsize=12)\n",
    "    plt.xticks(epochs, rotation=90)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.title('Training and validation loss', fontsize=16)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(epochs, acc, 'c+-', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'm.-', label='Val acc')\n",
    "    plt.xlabel('Epochs', fontsize=12)\n",
    "    plt.xticks(epochs, rotation=90)\n",
    "    plt.ylabel('Acc', fontsize=12)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.title('Training and validation acc', fontsize=16)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:34.393880Z",
     "start_time": "2020-04-19T10:21:34.020148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x302.4 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型很快就开始过拟合，考虑到训练样本很少，这一点也不奇怪。出于同样的原因，验证精度的波动很大。\n",
    "\n",
    "每次运行的结果可能会有所不同，因为训练样本数太少，所以模型性能严重依赖于你选择的 200 个样本，而样本是随机选择的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:38.214469Z",
     "start_time": "2020-04-19T10:21:34.395434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 4ms/sample - loss: 0.6930 - acc: 0.5100 - val_loss: 0.6955 - val_acc: 0.4954\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.4754 - acc: 0.8100 - val_loss: 0.7101 - val_acc: 0.5042\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.2500 - acc: 0.9750 - val_loss: 0.7159 - val_acc: 0.5122\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.1063 - acc: 0.9900 - val_loss: 0.7148 - val_acc: 0.5391\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0519 - acc: 1.0000 - val_loss: 0.7150 - val_acc: 0.5172\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0250 - acc: 1.0000 - val_loss: 0.7203 - val_acc: 0.5230\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.7335 - val_acc: 0.5238\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.7407 - val_acc: 0.5257\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 0.7448 - val_acc: 0.5254\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.7526 - val_acc: 0.5330\n"
     ]
    }
   ],
   "source": [
    "# non pretrained word embedding\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(max_words, embedding_dim, input_length=maxlen),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T10:21:43.017264Z",
     "start_time": "2020-04-19T10:21:38.215795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 23us/sample - loss: 1.6301 - acc: 0.5045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.630081245956421, 0.50452]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试\n",
    "test_dir = os.path.join(imdb_dir, 'test')\n",
    "\n",
    "texts, labels = [], []\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(test_dir, label_type)\n",
    "    for fname in sorted(os.listdir(dir_name)):\n",
    "        if fname[-4:] == '.txt':\n",
    "            with open(os.path.join(dir_name, fname)) as f:\n",
    "                texts.append(f.read())\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=maxlen)\n",
    "y_test = np.asarray(labels)\n",
    "\n",
    "# Load the first model\n",
    "model = tf.keras.models.load_model('./models/chap06-models/pretrained_glove_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
